{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import dltools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_imdb(data_dir,is_train):\n",
    "    data,labels = [],[]\n",
    "    for label in ('pos','neg'):\n",
    "        folder_name = os.path.join(data_dir,'train' if is_train else 'test',label)\n",
    "        for file in os.listdir(folder_name):\n",
    "            with open(os.path.join(folder_name,file),'rb') as f:\n",
    "                review = f.read().decode('utf-8').replace('\\n','')\n",
    "                data.append(review)\n",
    "                labels.append(1 if label == 'pos' else 0)\n",
    "    return data,labels\n",
    "\n",
    "data_dir = \"./aclimdb\"\n",
    "train_data = read_imdb(data_dir,is_train=True)\n",
    "print('train_len:',len(train_data)[0])\n",
    "for x ,y in zip(train_data[0][:3],train_data[1][3]):\n",
    "    print('label:',y,\"review:\",x[:60])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_token = dltools.token(train_data[0],token='word')\n",
    "vocab = dltools.Vocab(train_token,min_freq=5,reserved_token=[\"<pad>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dltools.set_figsize()\n",
    "dltools.plt.xlabel('# tokens perview')\n",
    "dltools.plt.ylabel('count')\n",
    "dltools.plt.hist([len(line) for line in train_tokens],bins=range(0,1000,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 500\n",
    "train_feature = torch.tensor([dltools.truncate_pad(vocab[line],num_steps,vocab['<pad>']) for line in train_token])\n",
    "print(train_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = dltools.load_array((train_feature,torch.tensor(train_data[1])),64)\n",
    "\n",
    "for x ,y in train_iter:\n",
    "    print(\"X:\",x.shape,\",y:\",y.shape)\n",
    "    break\n",
    "print('小批量数目：',len(train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_imdb(batch_size,num_steps=500):\n",
    "    data_dir = dltools.download_extract(\"aclImdb\",\"aclImdb\")\n",
    "    train_data = read_imdb(data_dir,True)\n",
    "    test_data = read_imdb(data_dir,False)\n",
    "    train_tokens = dltools.tokenize(train_data[0],token='word')\n",
    "    test_tokens = dltools.tokenize(test_data[0],token='word')\n",
    "    vocab = dltools.Vocab(train_tokens,min_freq=5)\n",
    "    train_features = torch.tensor([dltools.truincate_pad(vocab[line],num_steps,vocab[\"<pad>\"]) for line in train_tokens])\n",
    "    test_features = torch.tensor([dltools.truincate_pad(vocab[line],num_steps,vocab[\"<pad>\"]) for line in test_tokens])\n",
    "    train_iter = dltools.load_array((train_features,torch.tensor(train_data[1])),batch_size)\n",
    "    test_iter = dltools.load_array((test_features,torch.tensor(train_data[1])),batch_size,is_train=False)\n",
    "    return train_iter,test_iter,vocab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
